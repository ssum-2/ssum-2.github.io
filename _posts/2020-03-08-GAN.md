---
title: "Generative adversarial network; GAN"
classes: wide
categories:
  - Study
tags:
  - AI
  - ML
author_profile : true
use_math : true
last_modified_at: 2020-03-08
---
# 생성적 적대 신경망(GAN)


### 1. 소개 및 학습 원리

- **생성적 적대 신경망(Generative adversarial network; GAN)**

  -  [<Generative Adversarial Network>](https://arxiv.org/abs/1406.2661)(Ian J. Goodfellow, 2014) 라는 논문에서 처음 소개

- 단어의 의미로 살펴보는 GAN

  - Generative(생성적); 데이터 자체를 생성, 특성을 추출하는 모델보다 훨씬 어려운 Task를 수행 -> 학습도 복잡하고 어려움

    > ex. Text의 영역에서는 임의의 문장을 생성하는 것
    >
    > cf. 변분 오토인코더(variational auto encoder; VAE): latent variable의 공간을 정규분포 공간으로 강제로 맞춰주는 것

  - Adversarial(적대적); 생성 네트워크와 구분 네트워크 간 상반되는 `objective function`로 적대성이 생김
  
    - ![그림2: 생성자 – 구분자 도식](https://files.slack.com/files-pri/T25783BPY-F9SHTP6F9/picture2.png?pub_secret=6821873e68)
  
      > 위조지폐범은 경찰을 속이기 위해 점점 지폐 위조/제조 기술을 발전시키고, 경찰은 위조지폐범을 잡기 위해 점점 위폐를 찾는 기술을 발전시킨다. 시간이 흐르면 위조지폐범의 위폐 제조 기술은 완벽에 가깝게 발전할 것이다.
  
    - 위조 지폐를 만드는 사람(생성 네트워크; Generator) - 위조 지폐 감별사(구분 네트워크; Disciminator) 이 둘 사이에 `적대성` 조성
  
    - Label $y$, feature를 $x$ 라 할 때; $P(x|y)$
  
      -  구분자는 feature를 label에 매핑 -> feature와 label간의 상관관계에 집중, class간 경계를 학습
      -  생성자는 주어진 특정 label에서 feature를 예측 -> $y$일 수 있는 $x$를 얻는 방법 또는 그 확률에 집중, 각 클래스의 분포를 모델링
  
  - Network(네트워크); 생성자, 구분자의 구조가 인공신경망의 형태를 이루는 것
  
- GAN 모델 구조 살펴보기

  -  ![image-20200314195416166](https://imgur.com/0OH0SWV.png)

     -  Input `z` 를 받아 생성자가 `fake data` 생성 -> 구분자에 `fake data`와 `real data`를 넣고 구분

  -  MNIST Data-set 예시; 생성자 네트워크![image-20200314234522760](https://imgur.com/gb3jMCn.png)

     -  노이즈 z를 받아 특별한 조건 없이 랜덤한 노이즈값을 사용, NN or CNN을 통해  MNIST와 형태가 같은 fake data를 생성
     -  은닉층의 개수, 합성곱 필터의 크기 등을 조정(하이퍼파라미터)

  -  MNIST Data-set 예시; 구분자 네트워크

     ![image-20200315020430883](https://imgur.com/mxFre6g.png)

     - MNIST 형태의 데이터를 받아 real(1)과 fake(0)를 구별(판별)
     - 0~1 사이의 값이 결과 값으로 도출

- 목적함수로 살펴보는 GAN

  -  $min_Gmax_{D}V(D,G) = E_{x-P_{data}(x)}[logD(x)]+E_{z-P_{z}(z)}[log(1-D(G(z)))]$

     > $G$ = 생성자 / $D$ = 구분자 / $x$ = data / $z$ = random noise /  $x$~$P_{data}(x)$ = $x$를 $data$의 분포에서 샘플링함

  -  구분자의 입장에서는 maximize  => $logD(x), log(1-D(G(z)))$의 값이 커져야함

     -  $D(x)$ = 1, $D(G(z))$ = 0 일 때 최대화
     -  실제데이터는 1, 가짜데이터는 0으로 판단되어야 함

  -  생성자의 입장에서는 minimize => $E_{z-P_{z}(z)}[log(1-D(G(z)))]$ 의 값이 작아져야함

     -  $1-D(G(z))$ = 0 ---> $D(G(z))$ = 1 일 때 최소화
     -  생성자가 만든 가짜데이터가 구분자에서 1로 나와야 함

  -  각 목적이 *정확히 반대* => `적대성 발생`

  -  구분자가 목적함수를 달성한 최적상태일 때 생성자의 목적함수를 달성하는 것이 실제 데이터 분포 $P_{data}(x)$와 생성된 데이터의 분포인 $P_{g}(x)$가 같아지게 만드는 것과 같음 -> 옌센-섀넌 발산을 최소화하는 것과 같아짐

  -  Cf) 옌센-섀넌 발산; Jensen-Shannon divergence

     ​		$JSD(p‖q)=12KL(p‖M)+12KL(q‖M)$

     ​		$where,M=12(p+q)$

     -  KL divergence 2가지를 구하고 평균을 내는 방식으로 두 확률분포 간의 거리를 표현

        > 쿨백-라이블러 발산(Kullback-Leibler divergence, KL): 정보량의 차이,정보 엔트로피 차이, 확률분포간의 차이를 계산하는 함수

### 2. 모델 구현 및 학습

- 학습을 위해 필요한 사항

  손실함수와 최적화

  - 구분자의 목적함수를 손실함수의 형태로 변환

    - 실제데이터`label: 1`가 들어오는 경우  $E_{x-P_{data}(x)}[logD(x)]$의 값을 최소화

      => $min_{D}V(D,G)=-E_{x-P_{data}(x)}[logD(x)]$

      > cf. 교차 엔트로피 수식;  $H(P,Q)=−∑xP(x)log2Q(x)$
      >
      > `torch.nn.BCELoss()`

  - 생성자의 목적함수 변환

    - $max_{G}V(D,G)=E_{z-P_{z}(z)}[log(D(G(z)))]$로 바꾸어 사용
    - 위 수식에 마이너스를 붙이면 교차엔트로피 식과 같아짐

- 구현 및 학습은 주피터노트북파일 참조



### 3. 유명한 모델들과 원리

1. DCGAN

   - GAN에 합성곱 연산을 적용한 `DCGAN(Deep Convolutional GAN)`

   - 어떤 의미를 가지는 특성(표현)을 학습하여 데이터를 생성할 수 있음

   - ![image-20200315055409483](https://imgur.com/w23Q3hs.png)

     - 생성자는 `전치 합성곱 연산`을 통해 랜덤노이즈로부터 데이터를 생성
     - 생성자와 구분자에 `배치 정규화`를 사용
     - fully-connected network `사용 안함`
     - 생성자의 활성화 함수의 마지막에만 `하이퍼볼릭 탄젠트`사용, 그 외에는 `ReLU` 사용
     - 구분자의 활성화 함수에는 모두 `LeakyReLU` 사용

   - 잠재 공간 보간(Latent space interpolation)

     - 잠재변수 z의 공간을 탐색하는 방식; z에서 다른 값들은 고정하고 하나의 값만 연속적으로 바꿔보면서 결과를 관찰

   - `Word2vec`모델에서처럼 이미지에서도 벡터 간 연산이 가능하게 함

     >  z에서 안경 안 쓴 남자의 z를 빼고, 안경 안 쓴 여자의 z를 더해준 벡터를 생성자에 넣으면 안경 쓴 여자가 됨

   - `비지도학습에서도 특성을 배우는 과정이 가능함`을 DCGAN으로 증명함

   - Cf. 조건부 GAN(conditional GAN, cGAN), InfoGAN 등...

   

2. SRGAN

   - 슈퍼 레절루션 GAN(Super-resolutiaon GAN)

     - 슈퍼 레절루션; 저화질의 이미지를 입력받아 고화질로 변환하는 작업
     - ![image-20200315061015389](https://imgur.com/ddoqWsU.png)
       - SRResNet은 고화질 영상과 생성된 영상의 MSE를 최소화하는 방식으로 학습
       - SRGAN은 MSE에 추가생성 이미지가 실제 고화질 영상인지, 슈퍼레절루션을 거친 이미지인지 구분하는 GAN 손실을 추가해 학습 --> 훨씬 선명함

   - 슈퍼 레절루션 작업에서의 GAN의 역할

     - 세부적인 형태에 대한 정보가 사라진 저화질 영상 --> GAN을 통해 세부형태에 대한 특정 경우를 생성

     - 모드 붕괴(mode collapse); 생성자가 구분자를 속일 수 있는 특정 데이터만 만들어내는 현상

       => 슈퍼 레절루션에서는 *모드 붕괴현상이 진짜같은 특정 이미지를 만드는데 기여*

     - 진동(oscillation); 생성된 결과가 계속 변화하는 특성

       => 다양한 경우를 왔다 갔다하며 결과를 생성

       조건부GAN과 같이 추가적인 조건을 부여하면 완화됨

     

3. 텍스트 이미지 합성

   - 텍스트 이미지 합성(text to image synthesis); 텍스트를 받아 이미지를 생성
   - 네트워크 전체 구조 ![image-20200315062334900](https://imgur.com/RdkpISo.png)
     - 특정 문장 벡터화 + 랜덤노이즈 --> `생성자` --> 데이터생성 --> 생성된 데이터 + 벡터화 했던 문장(조건; condition) --> `구분자` --> ~
   - 실제이미지와 이미지를 묘사하는 텍스트가 구분자로 전달 -> 실제 데이터 분포 학습



4. Pix2Pix
   - 이미지를 조건으로 주고 이미지를 생성
   - ![image-20200315062815899](https://imgur.com/FRkK9lw.png)
     - 이미지 x를 조건으로 G(x) 생성한 뒤, 그 두 이미지가 진짜 쌍인지를 구분함
   - 활용범위가 다양함
     - ![image-20200315062924581](https://imgur.com/PhTiwXB.png)



5. CycleGAN과 DiscoGAN
   - CycleGAN; 실제 쌍 데이터가 필요없는 Pix2pix 모델
   - A 도메인 -> B 도메인으로의 변환 (그 반대도 적용) --> 도메인에서 생성된 이미지에 대해 복원(reconstruction) 손실함수적용 -->  도메인의 형태를 보존하면서 특성만 변환









